{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949170e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8187920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load in model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"./distilbert_ai_detector\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"./distilbert_ai_detector\")\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "    def preprocess_function(examples):\n",
    "        # Tokenize the text. `truncation=True` ensures texts longer than the model's max input size are cut.\n",
    "        # `padding=True` or handled by DataCollator later. Let's rely on DataCollator here.\n",
    "        return tokenizer(examples[\"text\"], truncation=True, max_length=512) # Adjust max_length if needed\n",
    "    \n",
    "    test_dir_path = os.path.join(os.getcwd(), \"test_data\")\n",
    "\n",
    "    test_files = [] # Add names of your test files here\n",
    "\n",
    "    data_frames = []\n",
    "    for i in range(len(test_files)):\n",
    "        file_path = os.path.join(test_dir_path, test_files[i])\n",
    "        data_frames.append(pd.read_json(file_path, lines=True))\n",
    "\n",
    "    test_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # --- Process and format dev dataset ---\n",
    "\n",
    "    # Label human text from dev set\n",
    "    human_df = pd.DataFrame(test_df['human_text'])\n",
    "    human_df.columns = ['text']\n",
    "    human_df['generated'] = 0\n",
    "\n",
    "    # Label AI text from dev set\n",
    "    ai_df = pd.DataFrame(test_df['machine_text'])\n",
    "    ai_df.columns = ['text']\n",
    "    ai_df['generated'] = 1\n",
    "\n",
    "    merged_df = pd.concat([human_df, ai_df], ignore_index=True)\n",
    "\n",
    "    test_df = merged_df[merged_df['text'] != \"\"]\n",
    "\n",
    "    # --- Preprocess Dev Data (Tokenization) ---\n",
    "\n",
    "    # Preprocess Data Start\n",
    "    texts = test_df['text'].tolist()\n",
    "    labels = test_df['generated'].tolist()\n",
    "\n",
    "    test_data = {\"text\": texts, \"labels\": labels}\n",
    "    test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "    # Apply the tokenizer to the datasets\n",
    "    tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "    # Remove the original 'text' column as it's no longer needed after tokenization\n",
    "    tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"text\"])\n",
    "\n",
    "    # Set the format to PyTorch tensors\n",
    "    tokenized_test_dataset.set_format(\"torch\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "        # Calculate precision, recall, F1 score with 'binary' average for binary classification\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,                    \n",
    "        data_collator=data_collator,            \n",
    "        compute_metrics=compute_metrics, \n",
    "    )\n",
    "\n",
    "    eval_results = trainer.evaluate(\n",
    "        eval_dataset=tokenized_test_dataset,\n",
    "    )\n",
    "\n",
    "    print(\"Evaluation results:\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99952017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before you run add test file names to test_files\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
